{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T18:34:27.662144Z",
     "start_time": "2025-11-29T18:34:27.656229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import ImageFilter\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Basic config\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Corruption labels\n",
    "CORRUPTION_NAMES = {\n",
    "    0: \"clean\",\n",
    "    1: \"gaussian_noise\",\n",
    "    2: \"blur\",\n",
    "    3: \"jpeg_compression\",\n",
    "}\n",
    "NUM_CORRUPTIONS = len(CORRUPTION_NAMES)\n",
    "\n",
    "DATA_ROOT = \"./data\"\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n"
   ],
   "id": "51df78d5d733875a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Corruption functions\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "def add_gaussian_noise(img: Image.Image, std: float = 0.1) -> Image.Image:\n",
    "    x = to_tensor(img)\n",
    "    noise = torch.randn_like(x) * std\n",
    "    x_noisy = torch.clamp(x + noise, 0.0, 1.0)\n",
    "    return to_pil(x_noisy)\n",
    "\n",
    "\n",
    "def add_blur(img: Image.Image, radius: float = 1.5) -> Image.Image:\n",
    "    return img.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "\n",
    "\n",
    "def add_jpeg_compression(img: Image.Image, downscale_factor: int = 2) -> Image.Image:\n",
    "    w, h = img.size\n",
    "    small_size = (w // downscale_factor, h // downscale_factor)\n",
    "    down = img.resize(small_size, Image.BILINEAR)\n",
    "    up = down.resize((w, h), Image.BILINEAR)\n",
    "    return up\n",
    "\n",
    "\n",
    "def apply_corruption(img: Image.Image, corruption_idx: int) -> Image.Image:\n",
    "    if corruption_idx == 0:\n",
    "        return img\n",
    "    elif corruption_idx == 1:\n",
    "        return add_gaussian_noise(img)\n",
    "    elif corruption_idx == 2:\n",
    "        return add_blur(img)\n",
    "    elif corruption_idx == 3:\n",
    "        return add_jpeg_compression(img)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid corruption_idx: {corruption_idx}\")\n"
   ],
   "id": "b6d028c8bca405a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Corrupted CIFAR-10 Dataset\n",
    "\n",
    "class CorruptedCIFAR10(Dataset):\n",
    "    def __init__(self, root: str, train: bool = True, download: bool = True):\n",
    "        self.base = torchvision.datasets.CIFAR10(\n",
    "            root=root,\n",
    "            train=train,\n",
    "            download=download,\n",
    "            transform=None,\n",
    "        )\n",
    "        self.num_corruptions = NUM_CORRUPTIONS\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.base) * self.num_corruptions\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        base_idx = idx // self.num_corruptions\n",
    "        corruption_idx = idx % self.num_corruptions\n",
    "\n",
    "        img, _ = self.base[base_idx]\n",
    "        img = apply_corruption(img, corruption_idx)\n",
    "        x = self.to_tensor(img)  # [C, H, W] in [0, 1]\n",
    "        y = corruption_idx\n",
    "        return x, y\n",
    "\n",
    "train_dataset = CorruptedCIFAR10(root=DATA_ROOT, train=True, download=True)\n",
    "test_dataset = CorruptedCIFAR10(root=DATA_ROOT, train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Test samples:\", len(test_dataset))\n",
    "print(\"Number of classes (corruptions):\", NUM_CORRUPTIONS)\n"
   ],
   "id": "94cb9fa162c7c86b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Look at some examples\n",
    "def show_batch(loader: DataLoader, n_images: int = 8):\n",
    "    x_batch, y_batch = next(iter(loader))\n",
    "    x_batch = x_batch[:n_images]\n",
    "    y_batch = y_batch[:n_images]\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_images, figsize=(n_images * 2, 2))\n",
    "    for i in range(n_images):\n",
    "        # print(f\"Currently doing the {i}th image:\")\n",
    "        img = x_batch[i].permute(1, 2, 0)  # [C,H,W] -> [H,W,C]\n",
    "        label = CORRUPTION_NAMES[int(y_batch[i].item())]\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(label, fontsize=8)\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_batch(train_loader, n_images=8)\n"
   ],
   "id": "736f62a4ff34a2a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Model Definition\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int = NUM_CORRUPTIONS):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 32x32 -> 16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 16x16 -> 8x8\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # -> [128, 1, 1]\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleCNN(num_classes=NUM_CORRUPTIONS).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(model)\n"
   ],
   "id": "bcfea9d89cee2d29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Train\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "    )\n"
   ],
   "id": "2208f9474ccce5ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_sample(model, loader, device, n_samples: int = 5):\n",
    "    model.eval()\n",
    "    x_batch, y_batch = next(iter(loader))\n",
    "    x_batch = x_batch[:n_samples].to(device)\n",
    "    y_batch = y_batch[:n_samples]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x_batch)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    x_batch_cpu = x_batch.cpu()\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_samples, figsize=(n_samples * 2, 2))\n",
    "    for i in range(n_samples):\n",
    "        img = x_batch_cpu[i].permute(1, 2, 0)\n",
    "        true_label = CORRUPTION_NAMES[int(y_batch[i].item())]\n",
    "        pred_label = CORRUPTION_NAMES[int(preds[i].item())]\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"T:{true_label}\\nP:{pred_label}\", fontsize=7)\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "predict_sample(model, test_loader, device, n_samples=8)\n"
   ],
   "id": "38843bca8ca43aeb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
